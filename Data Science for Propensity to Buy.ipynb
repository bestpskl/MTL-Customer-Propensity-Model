{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> <br> SIP2021 x MTL INTERNSHIP <br> <br>  Data Science for Propensity to Buy </center> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ---------- < Team Member > ---------- </h2>\n",
    "<h3> 1. Pasakorn Limchuchua <br> <br> 2. Thiranai Keatpimol </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> ---------- < Table of Contents > ---------- </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1. Introduction](#1.Introduction)\n",
    "    * [Project Assignment](#ProjectAssignment)\n",
    "    * [Project Scope](#ProjectScope)    \n",
    "* [2. Data Preprocessing](#2.DataPreprocessing)\n",
    "    * [Step 1 : Handle Categorical Variables](#Step1HCV)\n",
    "    * [Step 2 : Handle Numerical Variables](#Step2HNV)  \n",
    "    * [Step 3 : Handle High Correlation Variables](#Step3HHCV)\n",
    "    * [Step 4 : Outlier Handling](#Step4OH)  \n",
    "* [3. Model Development](#3.ModelDevelopment)\n",
    "    * [Step 1 : Variable Selection](#Step1VS)\n",
    "    * [Step 2,3,4 : Model Selection - Model Validation - Performance Testing](#Step234)\n",
    "* [4. Model Implementation](#4.ModelImplementation)\n",
    "    * [Interpret with Confusion Matrix](#ICM)\n",
    "    * [Interpret with SHAP Value](#ISV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='1.Introduction'> <h2> ---------- < 1. Introduction > ---------- </h2> </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ProjectAssignment'> <h3> Project Assignment </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":  To build model to predict customer propensity to buy product and find customer characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ProjectScope'> <h3> Project Scope </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ": We used the data as of '2019' to predict customers who are likely to repurchase <b> target product </b> in '2020' from an <b> Agent </b> channel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='2.DataPreprocessing'> <h2> ---------- < 2. Data Preprocessing > ---------- </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Import libraries and set display </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import shap\n",
    "import statsmodels.api as sm\n",
    "import statistics\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score, fbeta_score, classification_report, make_scorer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pd.set_option('display.max_columns',300)\n",
    "pd.set_option('display.max_rows',300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Load tabular data </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'D:\\2021\\Internship\\cu_internship_data_2019_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step1HCV'> <h3> <b> Step 1 : Handle Categorical Variables </b> </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Dropping unrelated records </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> GNDR </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to drop GNDR value = C because we did not focus on corperate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Dropping variables </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'BUSI_DT' </i></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to drop 'BUSI_DT' because all of them had the same value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['BUSI_DT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we want to keep 'PH_ID_BASE' which has unique value to filter other columns, but we will drop it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['GNDR'] != 'C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'JUV_LA_FLG' </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'JUV_LA_FLG' had a large difference between N and Y <br>\n",
    "We will check that 'JUV_LA_FLG' value = Y has affect on all target = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result, it had no effect -> We decided to drop 'JUV_LA_FLG' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['JUV_LA_FLG'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Filling missing records </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'MIB_LV' </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that 'MIB_LV' has 1.0 = critical health, 0 or NaN (from P'Folk) = good health and so on <br>\n",
    "We decided to fill NaN as 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.fillna({'MIB_LV' : 0}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. One-Hot Encoding </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.get_dummies(df_clean, columns =['EMPL_FLG', 'FIRST_AQUS_CHN', 'GNDR', 'INF_LEG_ANNT_FLG', 'INF_TKF_FLG',\n",
    "                                   'LAST_CHN', 'LIFE_STG', 'MAT_DUR_CHRCTR', 'ON_ANNT_FLG', 'PC_DUR_CHRCTR', 'PHLA_FLG'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped out one column per categorical data for preventing redundancy from get dummies<br>\n",
    "Except 'LIFE_STG' we will drop this column later. (we will use this column to fill NaN value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['EMPL_FLG_N', 'FIRST_AQUS_CHN_AF BANK', 'GNDR_F', 'INF_LEG_ANNT_FLG_N', 'INF_TKF_FLG_N', \n",
    "                    'LAST_CHN_AF BANK', 'MAT_DUR_CHRCTR_0', 'ON_ANNT_FLG_N', \n",
    "                    'PC_DUR_CHRCTR_0', 'PHLA_FLG_N'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 5. Order Encoding </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_dict = { 'SMILECLUB' : 1, 'PLATINUM' : 2, 'PRESTIGE' : 3}\n",
    "df_clean['CUST_TIER'] = df['CUST_TIER'].map(ct_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fill NaN as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.fillna({'CUST_TIER' : 0.0}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace Unknown Value with 1, Unknown Start with not Digit~Alphabet and End with Digit(or not)\n",
    "df_clean['CUST_TIER'].replace(regex=r'^[\\D]+[\\d]*$', value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scaler 'CUST_TIER' using Standardization (STD) ad MINMAX Normalization (MINMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaler = MinMaxScaler()\n",
    "sdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mm_r = df_clean[['PH_ID_BASE','CUST_TIER']].copy()\n",
    "df_sd_r = df_clean[['PH_ID_BASE','CUST_TIER']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mm_r_ft = mmscaler.fit_transform(df_mm_r)\n",
    "df_mm_r_ft = df_mm_r_ft[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_CUST_TIER'] = df_mm_r_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sd_r_ft = sdscaler.fit_transform(df_sd_r)\n",
    "df_sd_r_ft = df_sd_r_ft[:,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['STD_CUST_TIER'] = df_sd_r_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['CUST_TIER'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step2HNV'> <h3> <b> Step 2 : Handle Numerical Variables</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 1. Filling missing records </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'LOSS_RATIO_P3Y' </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_LOSS_RATIO_P3Y' majority in value was -0.001542 <br>\n",
    "We decided to fill 'STD_LOSS_RATIO_P3Y' value = NaN as -0.001542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.fillna({'STD_LOSS_RATIO_P3Y' : -0.001542}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'LOSS_RATIO_P3Y' </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'MINMAX_LOSS_RATIO_P3Y' majority in value was 0.000000 <br>\n",
    "We decided to fill 'MINMAX_LOSS_RATIO_P3Y' value = NaN as 0.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.fillna({'MINMAX_LOSS_RATIO_P3Y' : 0.000000}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> 'NUM_CHLDRN' </i> <b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'NUM_CHLDRN' has relationship with 'LIFE_STG' So, We use this relationship to fill NaN <br> <br>\n",
    "Our determination : <br>\n",
    "1. Observation with 'LIFE_STG' column : Family without children / Single adult / Single young adult / Kid and Teenager <br>\n",
    "We decided to fill NaN as 0 for Normalization and -1.189127 for Standardization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['STD_NUM_CHLDRN'] = np.where((df_clean['STD_NUM_CHLDRN'].isnull()) & (\n",
    "    (df_clean['LIFE_STG_Family without children'] == 1) | (df_clean['LIFE_STG_Single adult'] == 1) \n",
    "    | (df_clean['LIFE_STG_Single young adult'] == 1) | (df_clean['LIFE_STG_Kid and Teenager'] == 1)),\n",
    "                                         -1.189127, df_clean['STD_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_NUM_CHLDRN'] = np.where((df_clean['MINMAX_NUM_CHLDRN'].isnull()) & (\n",
    "    (df_clean['LIFE_STG_Family without children'] == 1) | (df_clean['LIFE_STG_Single adult'] == 1) \n",
    "    | (df_clean['LIFE_STG_Single young adult'] == 1) | (df_clean['LIFE_STG_Kid and Teenager'] == 1)),\n",
    "                                         0, df_clean['MINMAX_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'LIFE_STG' column : New married couple, we found that it's all value was 0 <br>\n",
    "We decided to fill NaN as 0 for Normalization and -1.189127 for Standardization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmc_notnull = len(df_clean['MINMAX_NUM_CHLDRN'][(df_clean['MINMAX_NUM_CHLDRN'].notnull())&(df_clean['LIFE_STG_New married couple'] == 1)])\n",
    "nmc_notnull_valuecount = df_clean['MINMAX_NUM_CHLDRN'][(df_clean['MINMAX_NUM_CHLDRN'].notnull())&(df_clean['LIFE_STG_New married couple'] == 1)].value_counts(dropna = False)\n",
    "print('New married couple not null:',nmc_notnull,'row', '\\n With values count:', nmc_notnull_valuecount,'row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['STD_NUM_CHLDRN'] = np.where((df_clean['STD_NUM_CHLDRN'].isnull()) & \n",
    "                                         (df_clean['LIFE_STG_New married couple'] == 1),\n",
    "                                         -1.189127, df_clean['STD_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_NUM_CHLDRN'] = np.where((df_clean['MINMAX_NUM_CHLDRN'].isnull()) & \n",
    "                                         (df_clean['LIFE_STG_New married couple'] == 1),\n",
    "                                         0, df_clean['MINMAX_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Observation with 'LIFE_STG' column : Family with children <br>\n",
    "We see that histrogram skewed right so we decided to fill NaN as 0.014493 (median & mode) or 1 child for Normalization<br>\n",
    "and -0.483409 for Standardization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_NUM_CHLDRN'][(df_clean['MINMAX_NUM_CHLDRN'].notnull()) & \n",
    "                              (df_clean['LIFE_STG_Family with children'] == 1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['STD_NUM_CHLDRN'] = np.where((df_clean['STD_NUM_CHLDRN'].isnull()) & \n",
    "                                         (df_clean['LIFE_STG_Family with children'] == 1), \n",
    "                                         -0.483409, df_clean['STD_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_NUM_CHLDRN'] = np.where((df_clean['MINMAX_NUM_CHLDRN'].isnull()) & \n",
    "                                         (df_clean['LIFE_STG_Family with children'] == 1), \n",
    "                                         0.014493, df_clean['MINMAX_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Observation with 'LIFE_STG' column : Retirement / Family with adolescents<br>\n",
    "We see that histrogram skewed right so we decided to fill NaN as 0.028986 (median & mode) or 2 children for Normalization<br>\n",
    "and 0.222309 for Standardization<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['STD_NUM_CHLDRN'] = np.where((df_clean['STD_NUM_CHLDRN'].isnull()) & (\n",
    "    (df_clean['LIFE_STG_Retirement'] == 1) | (df_clean['LIFE_STG_Family with adolescents'] == 1)), \n",
    "                                         0.222309, df_clean['STD_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['MINMAX_NUM_CHLDRN'] = np.where((df_clean['MINMAX_NUM_CHLDRN'].isnull()) & (\n",
    "    (df_clean['LIFE_STG_Retirement'] == 1) | (df_clean['LIFE_STG_Family with adolescents'] == 1)), \n",
    "                                         0.028986, df_clean['MINMAX_NUM_CHLDRN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dropped out one column per categorical data for preventing redundancy from get dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = 'LIFE_STG_Family with adolescents', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 2. Dropping missing records </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> DUR_TO_NEXT_ME_DT </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_DUR_TO_NEXT_ME_DT' and 'MINMAX_DUR_TO_NEXT_ME_DT' had low value : NaN compared to all distribution <br> <br>\n",
    "We will check that 'STD_DUR_TO_NEXT_ME_DT' and 'MINMAX_DUR_TO_NEXT_ME_DT' value = NaN has affect on all target = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result, it had no effect -> We decided to drop 'STD_DUR_TO_NEXT_ME_DT' and 'MINMAX_DUR_TO_NEXT_ME_DT' value = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dropna(subset = ['STD_DUR_TO_NEXT_ME_DT'], inplace = True)\n",
    "df_clean.dropna(subset = ['MINMAX_DUR_TO_NEXT_ME_DT'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> PPREM_LTD </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'PPREM_LTD' had low value : NaN compared to all distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check that 'STD_PPREM_LTD' and 'MINMAX_PPREM_LTD' value = NaN has affect on all target = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From result, it had no effect -> We decided to drop 'STD_PPREM_LTD' and 'MINMAX_PPREM_LTD' value = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dropna(subset = ['STD_PPREM_LTD'], inplace = True)\n",
    "df_clean.dropna(subset = ['MINMAX_PPREM_LTD'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3. Dropping variables </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> NUM_FULLY_PC_INF </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_NUM_FULLY_PC_INF' and 'MINMAX_NUM_FULLY_PC_INF' had only value = 0 <br> <br>\n",
    "We decided to drop 'STD_NUM_FULLY_PC_INF' and 'MINMAX_NUM_FULLY_PC_INF' column because the column which had all same value were impractical for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['STD_NUM_FULLY_PC_INF'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['MINMAX_NUM_FULLY_PC_INF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> NUM_PO_OTH_PROD_INF </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_NUM_PO_OTH_PROD_INF' and 'MINMAX_NUM_PO_OTH_PROD_INF' had only value = 0 <br> <br>\n",
    "We decided to drop 'STD_NUM_PO_OTH_PROD_INF' and 'MINMAX_NUM_PO_OTH_PROD_INF' column because the column which had all same value were impractical for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['STD_NUM_PO_OTH_PROD_INF'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['MINMAX_NUM_PO_OTH_PROD_INF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> PCT_PAR_PO_INF </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_PCT_PAR_PO_INF' and 'MINMAX_PCT_PAR_PO_INF' had only value = 0 <br> <br>\n",
    "We decided to drop 'STD_PCT_PAR_PO_INF' and 'MINMAX_PCT_PAR_PO_INF' column because the column which had all same value were impractical for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['STD_PCT_PAR_PO_INF'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['MINMAX_PCT_PAR_PO_INF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> SA_HB_BNFT_INF </i> </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_SA_HB_BNFT_INF' and 'MINMAX_SA_HB_BNFT_INF' had only value = 0 <br> <br>\n",
    "We decided to drop 'STD_SA_HB_BNFT_INF' and 'MINMAX_SA_HB_BNFT_INF' column because the column which had all same value were impractical for training model       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['STD_SA_HB_BNFT_INF'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['MINMAX_SA_HB_BNFT_INF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <i> SA_OTH_BNFT_INF </i> </b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that 'STD_SA_OTH_BNFT_INF' and 'MINMAX_SA_OTH_BNFT_INF' had only value = 0 <br> <br>\n",
    "We decided to drop 'STD_SA_OTH_BNFT_INF' and 'MINMAX_SA_OTH_BNFT_INF' column because the column which had all same value were impractical for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['STD_SA_OTH_BNFT_INF'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['MINMAX_SA_OTH_BNFT_INF'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 4. Dropping variables with condition </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our criteria : We decided to drop column which has these conditions : <br>\n",
    "1. has 1 possible outcome more than 99 % of data (from cell above) <br>\n",
    "2. and that possible outcome has relationship with all target = 1 more than 99 % (from cell below)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the possible outcome of 'MINMAX_AVG_PPREM_ST_AMT' has target class more than 99% of all target class <br>\n",
    "We decided to drop 'MINMAX_AVG_PPREM_ST_AMT' column <br>\n",
    "Similarly, we dropped 'STD_AVG_PPREM_ST_AMT' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['MINMAX_AVG_PPREM_ST_AMT'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['STD_AVG_PPREM_ST_AMT'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found that the possible outcome of 'MINMAX_PPREM_OTH_BNFT_L1Y' has target class more than 99% of all target class <br>\n",
    "We decided to drop 'MINMAX_PPREM_OTH_BNFT_L1Y' column <br>\n",
    "Similarly, we dropped 'STD_PPREM_OTH_BNFT_L1Y' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['MINMAX_PPREM_OTH_BNFT_L1Y'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['STD_PPREM_OTH_BNFT_L1Y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, we decided to drop 'MINMAX_NUM_REJ_CA_P3Y' and 'STD_NUM_REJ_CA_P3Y' because the majority of value = NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['MINMAX_NUM_REJ_CA_P3Y'], axis = 1, inplace = True)\n",
    "df_clean.drop(columns = ['STD_NUM_REJ_CA_P3Y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step3HHCV'> <h3> <b> Step 3 : Handle High Correlation Variables</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STD<br>\n",
    "Remove Column form One-Hot_encoding because it will give 1.00 correlation in each category itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.get_loc(\"MINMAX_CUST_TIER\")\n",
    "df_std.drop(columns = list(df_std.columns[104:241]), axis = 1, inplace = True) #MINMAX_AGE:MINMAX_CUST_TIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std.drop(columns = list(df_std.columns[0:6]), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df, threshold):\n",
    "    col_corr = set()\n",
    "    corr_matrix = df.corr().abs()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if (corr_matrix.iloc[i, j] >= threshold) and (corr_matrix.columns[j] not in col_corr):\n",
    "                colname = corr_matrix.columns[i]\n",
    "                col_corr.add(colname)\n",
    "                if colname in df.columns:\n",
    "                    del df[colname]\n",
    "    return df\n",
    "    \n",
    "correlation(df_std, 0.8) #0.8 is very strong correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step4OH'> <h3> <b> Step 4 : Outlier Handling</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std['PH_ID_BASE'] = df_clean['PH_ID_BASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std_oh = df_std.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_count = 0\n",
    "df_std_oh = df_std\n",
    "for i in df_std.columns:\n",
    "    #print(i)\n",
    "    threshold = df_std_oh[i].std()*10.5\n",
    "    \n",
    "    df_std_oh = df_std_oh[(df_std_oh[df_std_oh.columns[int(i_count)]] < threshold)]\n",
    "    df_std_oh = df_std_oh.reset_index(drop=True)\n",
    "    #print(df_std_oh.shape)\n",
    "    i_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = df_clean.copy()\n",
    "dfc.drop(columns = list(dfc.columns[6:202]), axis = 1, inplace = True)\n",
    "dfc.drop(columns = list(dfc.columns[44:46]), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.merge(dfc, df_std_oh, on='PH_ID_BASE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='3.ModelDevelopment'> <h2> ---------- < 3. Model Developing > ---------- </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step1VS'><h3> <b> Step 1 : Variable Selection</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Variable Selection With RF </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns = ['PH_ID_BASE'])\n",
    "x = df_clean.drop(columns = list(df_clean.columns[7:16])) #HLH_TRG_FLG:UNUL_KB_TRG_FLG\n",
    "y = df_clean['WL_AG_TRG_FLG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = rf.feature_importances_\n",
    "sorted_index_array = np.argsort(arr)\n",
    "sorted_array = arr[sorted_index_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = sorted_array[-40:]\n",
    "rslt_index = sorted_index_array[-40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_select = x.columns.to_numpy()[np.array(rslt_index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(df_clean, columns=col_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['PH_ID_BASE'] = df_clean['PH_ID_BASE']\n",
    "df_model['WL_AG_TRG_FLG'] = df_clean['WL_AG_TRG_FLG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove feature that have some correlation\n",
    "df_model.drop(columns = ['STD_NUM_PO_PURCH_L2Y', 'STD_NUM_RIDER_PURCH_L3Y', 'STD_NUM_RIDER_PURCH_L2Y'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='Step234'><h3> <b> Step 2,3,4 : Model Selection - Model Validation - Performance Testing</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_model.drop(columns= list(df_model.columns[37:42]), axis = 1)\n",
    "y = df_model['WL_AG_TRG_FLG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_valid, x_valid, y_train_valid, y_valid = train_test_split(x_train, y_train, test_size = 0.125, random_state = 42)\n",
    "#0.7 0.1 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random Forest Classifier</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rf_grid(x_train, y_train, x_test, y_test):\n",
    "\n",
    "    #Create Model\n",
    "    rf = RandomForestClassifier(n_estimators=100 , max_depth=10 , criterion='gini', min_samples_split=10, \n",
    "                                min_samples_leaf=4, max_features='auto', class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "    rf.fit(x_train, y_train)\n",
    "    y_pred = rf.predict(x_train)\n",
    "    #Matrics\n",
    "    acc = accuracy_score(y_train, y_pred)\n",
    "    bl_acc = balanced_accuracy_score(y_train, y_pred)\n",
    "    recall = recall_score(y_train, y_pred)\n",
    "    prec = precision_score(y_train, y_pred)\n",
    "    f3 = fbeta_score(y_train, y_pred, beta=3.0)\n",
    "    print('Training_set\\n')\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    print(confusion_matrix(y_train, y_pred))\n",
    "    print('Accuracy:', acc)\n",
    "    print('Balanced Accuracy:', bl_acc)\n",
    "    print('Recall:', recall)\n",
    "    print('Precision:', prec)\n",
    "    print('F3:', f3)\n",
    "    print('-'*50)\n",
    "    \n",
    "    y_pred_test = rf.predict(x_test)\n",
    "    acc_test = accuracy_score(y_test, y_pred_test)\n",
    "    bl_acc_test = balanced_accuracy_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    prec_test = precision_score(y_test, y_pred_test)\n",
    "    f3_test = fbeta_score(y_test, y_pred_test, beta=3.0)\n",
    "    print('\\nTest_set\\n')\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "    print('Accuracy:', acc_test)\n",
    "    print('Balanced Accuracy:', bl_acc_test)\n",
    "    print('Recall:', recall_test)\n",
    "    print('Precision:', prec_test)\n",
    "    print('F3:', f3_test)\n",
    "    print('-'*50)\n",
    "    \n",
    "    feat_importances = pd.Series(rf.feature_importances_, index=x.columns)\n",
    "    print(feat_importances.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Test Set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_rf_grid(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='4.ModelImplementation'><h2> ---------- < 4. Model Implementation > ---------- </h2> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ICM'> <h3> <b> Interpret with Confusion Matrix</b> </h2> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100 , max_depth=10 , criterion='gini', min_samples_split=10, \n",
    "                            min_samples_leaf=4 , class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "y_list = y_test.to_list()\n",
    "columns_list = list(x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TP predict 1, actual 1\n",
    "df_tp = pd.DataFrame(columns=columns_list)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    dict = {}\n",
    "    if (y_pred[i] == 1) & (y_list[i] == 1):\n",
    "        for j in x_test.iloc[[i]]:\n",
    "            dict[j] = float(x_test.iloc[[i]][j])\n",
    "        df_tp = df_tp.append(dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp['Target']='TP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TN predict 0, Actual 0\n",
    "df_tn = pd.DataFrame(columns=columns_list)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    dict = {}\n",
    "    if (y_pred[i] == 0) & (y_list[i] == 0):\n",
    "        for j in x_test.iloc[[i]]:\n",
    "            dict[j] = float(x_test.iloc[[i]][j])\n",
    "        df_tn = df_tn.append(dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tn['Target']='TN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP predict 1, Actual 0\n",
    "df_fp = pd.DataFrame(columns=columns_list)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    dict = {}\n",
    "    if (y_pred[i] == 1) & (y_list[i] == 0):\n",
    "        for j in x_test.iloc[[i]]:\n",
    "            dict[j] = float(x_test.iloc[[i]][j])\n",
    "        df_fp = df_fp.append(dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fp['Target'] = 'FP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FN predict 0, Actual 1\n",
    "df_fn = pd.DataFrame(columns=columns_list)\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    dict = {}\n",
    "    if (y_pred[i] == 0) & (y_list[i] == 1):\n",
    "        for j in x_test.iloc[[i]]:\n",
    "            dict[j] = float(x_test.iloc[[i]][j])\n",
    "        df_fn = df_fn.append(dict, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fn['Target'] = 'FN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confuse = pd.concat([df_tn, df_tp, df_fn, df_fp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(df_confuse.columns)\n",
    "col_list.remove('Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col_list:\n",
    "    sns.boxplot(x='Target', y=i, data=df_confuse)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class='anchor' id='ISV'> <h3> <b> Interpret with SHAP Value</b> </h3> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(rf).shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], x_test, plot_type=\"violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_copy = x_test.copy()\n",
    "x_test_copy['predicted'] = rf.predict(x_test)\n",
    "shap_values_x_test_copy = shap.TreeExplainer(rf).shap_values(x_test_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listshap_40 = x_test_copy.columns\n",
    "listpred = ['predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in listshap_40:\n",
    "    for j in listpred:\n",
    "        print(i, j)\n",
    "        shap.dependence_plot(i, shap_values_x_test_copy[1], x_test_copy, interaction_index=j, alpha=0.3, cmap = plt.get_cmap(\"cool\"))\n",
    "        print('-'*100)\n",
    "# dim 2 (i) dim 3 (j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
